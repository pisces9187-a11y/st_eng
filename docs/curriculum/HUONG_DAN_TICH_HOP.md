# H∆∞·ªõng D·∫´n T√≠ch H·ª£p Edge TTS cho H·ªá Th·ªëng H·ªçc Ti·∫øng Anh

## üìã T·ªïng Quan
Edge TTS l√† API text-to-speech mi·ªÖn ph√≠ c·ªßa Microsoft, h·ªó tr·ª£ nhi·ªÅu gi·ªçng n√≥i ch·∫•t l∆∞·ª£ng cao. H∆∞·ªõng d·∫´n n√†y gi√∫p b·∫°n t√≠ch h·ª£p v√†o h·ªá th·ªëng h·ªçc ti·∫øng Anh.

---

## üéØ C√°c Gi·ªçng Ti·∫øng Anh Ph·ªï Bi·∫øn

### üá∫üá∏ **Ti·∫øng Anh M·ªπ (en-US)** - Khuy√™n d√πng cho h·ªçc vi√™n
| T√™n Gi·ªçng | Gi·ªõi T√≠nh | ƒê·∫∑c ƒêi·ªÉm | Ph√π H·ª£p Cho |
|-----------|-----------|----------|-------------|
| `en-US-AriaNeural` | N·ªØ | Gi·ªçng n·ªØ r√µ r√†ng, t·ª± nhi√™n | H·ªçc t·ª´ v·ª±ng, h·ªôi tho·∫°i |
| `en-US-GuyNeural` | Nam | Gi·ªçng nam ·∫•m, chu·∫©n | B√†i ƒë·ªçc, c√¢u chuy·ªán |
| `en-US-JennyNeural` | N·ªØ | Gi·ªçng tr·∫ª trung, nƒÉng ƒë·ªông | H·ªçc sinh, thanh thi·∫øu ni√™n |
| `en-US-DavisNeural` | Nam | Gi·ªçng nam tr·∫ßm, chuy√™n nghi·ªáp | N·ªôi dung h·ªçc thu·∫≠t |
| `en-US-AnaNeural` | N·ªØ (tr·∫ª em) | Gi·ªçng em b√© | H·ªçc vi√™n nh·ªè tu·ªïi |

### üá¨üáß **Ti·∫øng Anh Anh (en-GB)** - Cho h·ªçc vi√™n mu·ªën gi·ªçng British
| T√™n Gi·ªçng | Gi·ªõi T√≠nh | ƒê·∫∑c ƒêi·ªÉm |
|-----------|-----------|----------|
| `en-GB-SoniaNeural` | N·ªØ | Chu·∫©n BBC, sang tr·ªçng |
| `en-GB-RyanNeural` | Nam | L·ªãch l√£m, chuy√™n nghi·ªáp |
| `en-GB-LibbyNeural` | N·ªØ | Tr·∫ª trung, hi·ªán ƒë·∫°i |

### üá¶üá∫ **Ti·∫øng Anh √öc (en-AU)**
- `en-AU-NatashaNeural` (N·ªØ)
- `en-AU-WilliamNeural` (Nam)

### üá®üá¶ **Ti·∫øng Anh Canada (en-CA)**
- `en-CA-ClaraNeural` (N·ªØ)
- `en-CA-LiamNeural` (Nam)

### üáÆüá≥ **Ti·∫øng Anh ·∫§n ƒê·ªô (en-IN)**
- `en-IN-NeerjaNeural` (N·ªØ)
- `en-IN-PrabhatNeural` (Nam)

---

## ‚ö° C√†i ƒê·∫∑t Nhanh

```bash
pip install edge-tts
```

---

## üîß C√°c C√°ch T√≠ch H·ª£p

### **Ph∆∞∆°ng √Ån 1: T√≠ch H·ª£p ƒê∆°n Gi·∫£n (C∆° B·∫£n)**
Ph√π h·ª£p cho: ·ª®ng d·ª•ng nh·ªè, ch·ª©c nƒÉng ph√°t √¢m t·ª´ v·ª±ng

```python
import edge_tts
import asyncio

async def text_to_speech_simple(text, voice="en-US-AriaNeural"):
    """
    Chuy·ªÉn vƒÉn b·∫£n th√†nh gi·ªçng n√≥i v√† l∆∞u file
    
    Args:
        text: VƒÉn b·∫£n c·∫ßn ƒë·ªçc
        voice: T√™n gi·ªçng (m·∫∑c ƒë·ªãnh: en-US-AriaNeural)
    
    Returns:
        ƒê∆∞·ªùng d·∫´n file audio
    """
    output_file = "output.mp3"
    communicate = edge_tts.Communicate(text, voice)
    await communicate.save(output_file)
    return output_file

# S·ª≠ d·ª•ng
asyncio.run(text_to_speech_simple("Hello, welcome to English learning!"))
```

### **Ph∆∞∆°ng √Ån 2: T√≠ch H·ª£p V·ªõi T√πy Ch·ªânh (Trung C·∫•p)**
Ph√π h·ª£p cho: T√πy ch·ªânh t·ªëc ƒë·ªô, cao ƒë·ªô gi·ªçng n√≥i

```python
import edge_tts
import asyncio

async def text_to_speech_advanced(
    text, 
    voice="en-US-AriaNeural",
    rate=0,      # T·ªëc ƒë·ªô: -50 ƒë·∫øn +50 (%)
    pitch=0,     # Cao ƒë·ªô: -20 ƒë·∫øn +20 (Hz)
    output_file="output.mp3"
):
    """
    Chuy·ªÉn vƒÉn b·∫£n v·ªõi t√πy ch·ªânh chi ti·∫øt
    
    Args:
        text: VƒÉn b·∫£n c·∫ßn ƒë·ªçc
        voice: T√™n gi·ªçng
        rate: T·ªëc ƒë·ªô ƒë·ªçc (0 = b√¨nh th∆∞·ªùng, +10 = nhanh h∆°n 10%, -10 = ch·∫≠m h∆°n 10%)
        pitch: Cao ƒë·ªô gi·ªçng (0 = b√¨nh th∆∞·ªùng)
        output_file: T√™n file ƒë·∫ßu ra
    
    Returns:
        ƒê∆∞·ªùng d·∫´n file audio
    """
    rate_str = f"{rate:+d}%"
    pitch_str = f"{pitch:+d}Hz"
    
    communicate = edge_tts.Communicate(
        text, 
        voice,
        rate=rate_str,
        pitch=pitch_str
    )
    
    await communicate.save(output_file)
    return output_file

# S·ª≠ d·ª•ng
asyncio.run(text_to_speech_advanced(
    "This is a slow speech for beginners",
    voice="en-US-JennyNeural",
    rate=-20,  # Ch·∫≠m h∆°n 20% cho ng∆∞·ªùi m·ªõi h·ªçc
    pitch=0
))
```

### **Ph∆∞∆°ng √Ån 3: Class T√°i S·ª≠ D·ª•ng (Chuy√™n Nghi·ªáp)**
Ph√π h·ª£p cho: H·ªá th·ªëng l·ªõn, nhi·ªÅu ch·ª©c nƒÉng

```python
import edge_tts
import asyncio
from typing import Optional
import os

class EnglishTTS:
    """Class qu·∫£n l√Ω Text-to-Speech cho h·ªá th·ªëng h·ªçc ti·∫øng Anh"""
    
    # Danh s√°ch gi·ªçng ƒë·ªÅ xu·∫•t
    VOICES = {
        "us_female_clear": "en-US-AriaNeural",      # N·ªØ M·ªπ r√µ r√†ng
        "us_male_standard": "en-US-GuyNeural",       # Nam M·ªπ chu·∫©n
        "us_female_young": "en-US-JennyNeural",      # N·ªØ M·ªπ tr·∫ª
        "us_male_professional": "en-US-DavisNeural", # Nam M·ªπ chuy√™n nghi·ªáp
        "gb_female": "en-GB-SoniaNeural",            # N·ªØ Anh
        "gb_male": "en-GB-RyanNeural",               # Nam Anh
    }
    
    # C·∫•u h√¨nh t·ªëc ƒë·ªô theo tr√¨nh ƒë·ªô
    SPEED_LEVELS = {
        "beginner": -20,    # Ng∆∞·ªùi m·ªõi: ch·∫≠m 20%
        "intermediate": 0,  # Trung c·∫•p: b√¨nh th∆∞·ªùng
        "advanced": +10,    # N√¢ng cao: nhanh 10%
    }
    
    def __init__(self, output_dir: str = "audio_cache"):
        """
        Kh·ªüi t·∫°o TTS engine
        
        Args:
            output_dir: Th∆∞ m·ª•c l∆∞u file audio
        """
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)
    
    async def generate_speech(
        self,
        text: str,
        voice_key: str = "us_female_clear",
        speed_level: str = "intermediate",
        filename: Optional[str] = None
    ) -> str:
        """
        T·∫°o file audio t·ª´ vƒÉn b·∫£n
        
        Args:
            text: VƒÉn b·∫£n c·∫ßn ƒë·ªçc
            voice_key: Key c·ªßa gi·ªçng n√≥i (xem VOICES)
            speed_level: Tr√¨nh ƒë·ªô h·ªçc vi√™n (beginner/intermediate/advanced)
            filename: T√™n file t√πy ch·ªânh (kh√¥ng bao g·ªìm ƒëu√¥i)
        
        Returns:
            ƒê∆∞·ªùng d·∫´n file audio ƒë√£ t·∫°o
        """
        if not text.strip():
            raise ValueError("Text kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng")
        
        # L·∫•y voice name
        voice = self.VOICES.get(voice_key, self.VOICES["us_female_clear"])
        
        # L·∫•y t·ªëc ƒë·ªô
        rate = self.SPEED_LEVELS.get(speed_level, 0)
        rate_str = f"{rate:+d}%"
        
        # T·∫°o t√™n file
        if filename is None:
            # T·∫°o t√™n file t·ª± ƒë·ªông t·ª´ hash c·ªßa text
            import hashlib
            text_hash = hashlib.md5(text.encode()).hexdigest()[:8]
            filename = f"{voice_key}_{speed_level}_{text_hash}"
        
        output_path = os.path.join(self.output_dir, f"{filename}.mp3")
        
        # Ki·ªÉm tra cache
        if os.path.exists(output_path):
            return output_path
        
        # T·∫°o audio
        communicate = edge_tts.Communicate(text, voice, rate=rate_str)
        await communicate.save(output_path)
        
        return output_path
    
    async def generate_word_pronunciation(
        self,
        word: str,
        accent: str = "us"  # "us" ho·∫∑c "gb"
    ) -> str:
        """
        T·∫°o audio ph√°t √¢m t·ª´ v·ª±ng
        
        Args:
            word: T·ª´ c·∫ßn ph√°t √¢m
            accent: Gi·ªçng M·ªπ (us) ho·∫∑c Anh (gb)
        
        Returns:
            ƒê∆∞·ªùng d·∫´n file audio
        """
        voice_key = "us_female_clear" if accent == "us" else "gb_female"
        filename = f"word_{word.lower().replace(' ', '_')}_{accent}"
        
        return await self.generate_speech(
            text=word,
            voice_key=voice_key,
            speed_level="beginner",  # Ph√°t √¢m t·ª´ th√¨ ch·∫≠m
            filename=filename
        )
    
    async def generate_sentence_audio(
        self,
        sentence: str,
        student_level: str = "intermediate",
        voice_type: str = "female"  # "female" ho·∫∑c "male"
    ) -> str:
        """
        T·∫°o audio cho c√¢u
        
        Args:
            sentence: C√¢u c·∫ßn ƒë·ªçc
            student_level: Tr√¨nh ƒë·ªô h·ªçc vi√™n
            voice_type: Gi·ªçng nam/n·ªØ
        
        Returns:
            ƒê∆∞·ªùng d·∫´n file audio
        """
        if voice_type == "female":
            voice_key = "us_female_clear"
        else:
            voice_key = "us_male_standard"
        
        return await self.generate_speech(
            text=sentence,
            voice_key=voice_key,
            speed_level=student_level
        )
    
    @staticmethod
    async def list_all_voices() -> list:
        """
        L·∫•y danh s√°ch t·∫•t c·∫£ gi·ªçng n√≥i c√≥ s·∫µn
        
        Returns:
            List c√°c gi·ªçng n√≥i
        """
        voices = await edge_tts.list_voices()
        return [
            {
                "name": v["ShortName"],
                "locale": v["Locale"],
                "gender": v["Gender"],
                "display": f"{v['ShortName']} - {v['Locale']} ({v['Gender']})"
            }
            for v in voices
            if v["Locale"].startswith("en-")  # Ch·ªâ l·∫•y gi·ªçng ti·∫øng Anh
        ]


# ===== C√ÅCH S·ª¨ D·ª§NG =====

async def main():
    # Kh·ªüi t·∫°o TTS engine
    tts = EnglishTTS(output_dir="my_audio_files")
    
    # V√≠ d·ª• 1: Ph√°t √¢m t·ª´ v·ª±ng
    word_audio = await tts.generate_word_pronunciation("beautiful", accent="us")
    print(f"Word audio: {word_audio}")
    
    # V√≠ d·ª• 2: ƒê·ªçc c√¢u cho ng∆∞·ªùi m·ªõi h·ªçc
    sentence = "The weather is nice today."
    sentence_audio = await tts.generate_sentence_audio(
        sentence,
        student_level="beginner",
        voice_type="female"
    )
    print(f"Sentence audio: {sentence_audio}")
    
    # V√≠ d·ª• 3: ƒê·ªçc ƒëo·∫°n vƒÉn cho ng∆∞·ªùi n√¢ng cao
    paragraph = """
    Machine learning is a subset of artificial intelligence. 
    It enables computers to learn from data without being explicitly programmed.
    """
    advanced_audio = await tts.generate_speech(
        text=paragraph,
        voice_key="us_male_professional",
        speed_level="advanced"
    )
    print(f"Advanced audio: {advanced_audio}")
    
    # V√≠ d·ª• 4: L·∫•y danh s√°ch t·∫•t c·∫£ gi·ªçng ti·∫øng Anh
    all_voices = await tts.list_all_voices()
    print(f"\nC√≥ {len(all_voices)} gi·ªçng ti·∫øng Anh:")
    for v in all_voices[:5]:  # In 5 gi·ªçng ƒë·∫ßu
        print(f"  - {v['display']}")

if __name__ == "__main__":
    asyncio.run(main())
```

---

## üéì Use Cases C·ª• Th·ªÉ Cho H·ªçc Ti·∫øng Anh

### 1Ô∏è‚É£ **Flashcard H·ªçc T·ª´ V·ª±ng**
```python
async def create_flashcard_audio(word, definition, example):
    tts = EnglishTTS()
    
    # Ph√°t √¢m t·ª´
    word_audio = await tts.generate_word_pronunciation(word)
    
    # ƒê·ªçc ƒë·ªãnh nghƒ©a
    definition_audio = await tts.generate_speech(
        definition,
        voice_key="us_female_clear",
        speed_level="beginner"
    )
    
    # ƒê·ªçc v√≠ d·ª•
    example_audio = await tts.generate_sentence_audio(
        example,
        student_level="intermediate"
    )
    
    return {
        "word": word_audio,
        "definition": definition_audio,
        "example": example_audio
    }
```

### 2Ô∏è‚É£ **Luy·ªán Nghe V·ªõi Nhi·ªÅu Gi·ªçng**
```python
async def create_listening_exercise(text, num_voices=3):
    """T·∫°o c√πng n·ªôi dung v·ªõi nhi·ªÅu gi·ªçng kh√°c nhau"""
    tts = EnglishTTS()
    voices = ["us_female_clear", "us_male_standard", "gb_female"]
    
    audio_files = []
    for voice in voices[:num_voices]:
        audio = await tts.generate_speech(
            text,
            voice_key=voice,
            speed_level="intermediate"
        )
        audio_files.append(audio)
    
    return audio_files
```

### 3Ô∏è‚É£ **Dictation (Ch√≠nh T·∫£)**
```python
async def create_dictation_levels(sentence):
    """T·∫°o 3 m·ª©c ƒë·ªô: ch·∫≠m -> b√¨nh th∆∞·ªùng -> nhanh"""
    tts = EnglishTTS()
    
    levels = {
        "slow": await tts.generate_speech(
            sentence, 
            speed_level="beginner"
        ),
        "normal": await tts.generate_speech(
            sentence,
            speed_level="intermediate"
        ),
        "fast": await tts.generate_speech(
            sentence,
            speed_level="advanced"
        )
    }
    
    return levels
```

### 4Ô∏è‚É£ **So S√°nh Gi·ªçng M·ªπ vs Anh**
```python
async def compare_accents(word_or_sentence):
    tts = EnglishTTS()
    
    us_audio = await tts.generate_speech(
        word_or_sentence,
        voice_key="us_female_clear"
    )
    
    gb_audio = await tts.generate_speech(
        word_or_sentence,
        voice_key="gb_female"
    )
    
    return {"american": us_audio, "british": gb_audio}
```

---

## üí° L∆∞u √ù Quan Tr·ªçng

### ‚úÖ **N√™n L√†m**
1. **Cache audio**: L∆∞u file ƒë√£ t·∫°o ƒë·ªÉ tr√°nh t·∫°o l·∫°i
2. **X·ª≠ l√Ω b·∫•t ƒë·ªìng b·ªô**: D√πng `async/await` cho hi·ªáu su·∫•t t·ªët
3. **T√πy ch·ªânh t·ªëc ƒë·ªô**: 
   - Ng∆∞·ªùi m·ªõi: `-20%` ƒë·∫øn `-30%`
   - Trung c·∫•p: `0%`
   - N√¢ng cao: `+10%` ƒë·∫øn `+20%`
4. **Ch·ªçn gi·ªçng ph√π h·ª£p**:
   - H·ªçc sinh nh·ªè: `JennyNeural`, `AnaNeural`
   - Ng∆∞·ªùi l·ªõn: `AriaNeural`, `GuyNeural`
   - H·ªçc thu·∫≠t: `DavisNeural`

### ‚ùå **Tr√°nh L√†m**
1. Kh√¥ng d√πng `asyncio.run()` nhi·ªÅu l·∫ßn trong c√πng 1 ch∆∞∆°ng tr√¨nh
2. Kh√¥ng t·∫°o audio cho vƒÉn b·∫£n qu√° d√†i (>5000 k√Ω t·ª±) - n√™n chia nh·ªè
3. Kh√¥ng qu√™n x·ª≠ l√Ω l·ªói khi m·∫°ng kh√¥ng ·ªïn ƒë·ªãnh

### ‚ö†Ô∏è **Gi·ªõi H·∫°n**
- **Mi·ªÖn ph√≠**: Kh√¥ng gi·ªõi h·∫°n, nh∆∞ng c·∫ßn internet
- **ƒê·ªô tr·ªÖ**: ~1-3 gi√¢y cho c√¢u ng·∫Øn
- **Ch·∫•t l∆∞·ª£ng**: MP3, t·ªët cho h·ªçc t·∫≠p

---

## üîå T√≠ch H·ª£p V·ªõi Framework

### **Flask/FastAPI**
```python
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel

app = FastAPI()
tts = EnglishTTS()

class TTSRequest(BaseModel):
    text: str
    voice: str = "us_female_clear"
    level: str = "intermediate"

@app.post("/api/tts")
async def generate_tts(request: TTSRequest):
    try:
        audio_path = await tts.generate_speech(
            request.text,
            voice_key=request.voice,
            speed_level=request.level
        )
        return {"audio_url": f"/audio/{os.path.basename(audio_path)}"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
```

### **Django**
```python
from django.http import JsonResponse
from asgiref.sync import async_to_sync
import asyncio

def generate_audio_view(request):
    text = request.POST.get('text')
    voice = request.POST.get('voice', 'us_female_clear')
    
    tts = EnglishTTS()
    audio_path = async_to_sync(tts.generate_speech)(
        text,
        voice_key=voice
    )
    
    return JsonResponse({"audio_url": f"/media/audio/{os.path.basename(audio_path)}"})
```

---

## üìä So S√°nh Gi·ªçng N√≥i

| Gi·ªçng | T·ªëc ƒê·ªô T·ª± Nhi√™n | ƒê·ªô R√µ R√†ng | Ph√π H·ª£p H·ªçc |
|-------|------------------|------------|-------------|
| AriaNeural (US-F) | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚úÖ T·ªët nh·∫•t |
| GuyNeural (US-M) | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚úÖ R·∫•t t·ªët |
| JennyNeural (US-F) | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚úÖ T·ªët (Tr·∫ª) |
| SoniaNeural (GB-F) | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚úÖ Anh chu·∫©n |

---

## üöÄ B·∫Øt ƒê·∫ßu Nhanh (Quick Start)

```python
import edge_tts
import asyncio

# Code t·ªëi thi·ªÉu ƒë·ªÉ ch·∫°y
async def quick_demo():
    text = "Hello! Welcome to English learning with Edge TTS."
    communicate = edge_tts.Communicate(text, "en-US-AriaNeural")
    await communicate.save("hello.mp3")
    print("‚úÖ Audio saved to hello.mp3")

asyncio.run(quick_demo())
```

---

## üìû H·ªó Tr·ª£

- **L·ªói th∆∞·ªùng g·∫∑p**: Ki·ªÉm tra k·∫øt n·ªëi internet
- **Gi·ªçng kh√¥ng ho·∫°t ƒë·ªông**: D√πng `edge_tts.list_voices()` ƒë·ªÉ xem danh s√°ch m·ªõi nh·∫•t
- **Performance**: D√πng caching v√† x·ª≠ l√Ω background tasks

---

**Ch√∫c b·∫°n t√≠ch h·ª£p th√†nh c√¥ng! üéâ**
