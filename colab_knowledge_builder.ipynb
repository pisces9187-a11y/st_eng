{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üèóÔ∏è Colab Knowledge Builder\n",
                "\n",
                "This notebook runs on Google Colab (using T4 GPU) to process your PDF/Docx files and build a local Vector Database.\n",
                "\n",
                "**Steps:**\n",
                "1. Install Dependencies\n",
                "2. Clone your GitHub Repo (to get the `source` files)\n",
                "3. Process Documents\n",
                "4. Generate Embeddings & Vector DB\n",
                "5. Zip and Download the Database"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title 1. Install Dependencies\n",
                "!pip install -q langchain langchain-community langchain-text-splitters sentence-transformers chromadb pypdf python-docx docx2txt"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title 2. Clone Repository\n",
                "import os\n",
                "import shutil\n",
                "\n",
                "# ‚ö†Ô∏è CHANGE THIS TO YOUR REPO URL\n",
                "REPO_URL = \"https://github.com/pisces9187-a11y/st_eng.git\"\n",
                "\n",
                "REPO_NAME = REPO_URL.split(\"/\")[-1].replace(\".git\", \"\")\n",
                "\n",
                "if os.path.exists(REPO_NAME):\n",
                "    shutil.rmtree(REPO_NAME)\n",
                "\n",
                "!git clone {REPO_URL}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title 3. Define Parsing Functions (Robust)\n",
                "from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader\n",
                "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
                "import glob\n",
                "\n",
                "SOURCE_DIR = f\"{REPO_NAME}/source\"  # Expects a 'source' folder in your repo\n",
                "\n",
                "def load_documents(source_dir):\n",
                "    documents = []\n",
                "    \n",
                "    # 1. Find all files\n",
                "    pdf_files = glob.glob(f\"{source_dir}/**/*.pdf\", recursive=True)\n",
                "    docx_files = glob.glob(f\"{source_dir}/**/*.docx\", recursive=True)\n",
                "    \n",
                "    print(f\"Found {len(pdf_files)} PDFs and {len(docx_files)} Docx files.\")\n",
                "    \n",
                "    # 2. Load PDFs safely\n",
                "    for file_path in pdf_files:\n",
                "        try:\n",
                "            loader = PyPDFLoader(file_path)\n",
                "            docs = loader.load()\n",
                "            documents.extend(docs)\n",
                "            print(f\"‚úÖ Loaded: {os.path.basename(file_path)}\")\n",
                "        except Exception as e:\n",
                "            print(f\"‚ùå Error loading {os.path.basename(file_path)}: {e}\")\n",
                "\n",
                "    # 3. Load Docx safely\n",
                "    for file_path in docx_files:\n",
                "        try:\n",
                "            loader = Docx2txtLoader(file_path)\n",
                "            docs = loader.load()\n",
                "            documents.extend(docs)\n",
                "            print(f\"‚úÖ Loaded: {os.path.basename(file_path)}\")\n",
                "        except Exception as e:\n",
                "            print(f\"‚ùå Error loading {os.path.basename(file_path)}: {e}\")\n",
                "            \n",
                "    print(f\"Total documents loaded: {len(documents)}\")\n",
                "    return documents\n",
                "\n",
                "def split_text(documents):\n",
                "    text_splitter = RecursiveCharacterTextSplitter(\n",
                "        chunk_size=1000,\n",
                "        chunk_overlap=200,\n",
                "        length_function=len,\n",
                "        add_start_index=True,\n",
                "    )\n",
                "    if not documents:\n",
                "        print(\"‚ö†Ô∏è No documents to split!\")\n",
                "        return []\n",
                "    \n",
                "    chunks = text_splitter.split_documents(documents)\n",
                "    print(f\"Split into {len(chunks)} chunks.\")\n",
                "    return chunks"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title 4. Build Vector DB (Using GPU)\n",
                "from langchain_community.vectorstores import Chroma\n",
                "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
                "import torch\n",
                "\n",
                "# Check for GPU\n",
                "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
                "print(f\"Using device: {device}\")\n",
                "\n",
                "# Initialize Embedding Model\n",
                "embedding_function = HuggingFaceEmbeddings(\n",
                "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
                "    model_kwargs={'device': device}\n",
                ")\n",
                "\n",
                "# Load and Split\n",
                "docs = load_documents(SOURCE_DIR)\n",
                "chunks = split_text(docs)\n",
                "\n",
                "# Persist DB\n",
                "CHROMA_PATH = \"chroma_db\"\n",
                "if os.path.exists(CHROMA_PATH):\n",
                "    shutil.rmtree(CHROMA_PATH)\n",
                "\n",
                "if chunks:\n",
                "    db = Chroma.from_documents(\n",
                "        documents=chunks, \n",
                "        embedding=embedding_function, \n",
                "        persist_directory=CHROMA_PATH\n",
                "    )\n",
                "    print(f\"‚úÖ Database processed and saved to '{CHROMA_PATH}'.\")\n",
                "else:\n",
                "    print(\"‚ùå No chunks created. Database not built.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title 5. Zip and Download\n",
                "if os.path.exists(\"chroma_db\"):\n",
                "    !zip -r chroma_db.zip chroma_db\n",
                "    from google.colab import files\n",
                "    files.download('chroma_db.zip')\n",
                "else:\n",
                "    print(\"‚ùå No database to zip.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}